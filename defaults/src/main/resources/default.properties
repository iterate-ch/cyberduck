#
# Copyright (c) 2002-2022 iterate GmbH. All rights reserved.
# https://cyberduck.io/
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
logging=ERROR
logging.archives=5

donate.reminder=-1
donate.reminder.suppress.enable=false
# in days
donate.reminder.interval=0
donate.reminder.date=0

defaulthandler.reminder=true

mail.feedback=mailto:support@cyberduck.io

website.donate=https://cyberduck.io/donate/
website.home=https://cyberduck.io/
website.help=https://help.cyberduck.io/
website.bug=https://trac.cyberduck.io/newticket?version={0}
website.crash=https://crash.cyberduck.io/report
website.cli=https://duck.sh/
website.license=https://cyberduck.io/license
website.acknowledgments=https://cyberduck.io/acknowledgments
website.privacypolicy=https://cyberduck.io/privacy/

rendezvous.enable=true
rendezvous.loopback.suppress=true
rendezvous.notification.limit=0

growl.enable=true

path.symboliclink.resolve=false
# Normalize path names
path.normalize=true
path.normalize.unicode=false

local.alias.resolve=true
local.symboliclink.resolve=false
local.normalize.prefix=false
local.normalize.unicode=true
local.normalize.tilde=true
local.delimiter=/
local.temporaryfiles.shortening.threshold=240

application.identifier=io.cyberduck
application.name=Cyberduck
application.container.name=duck
application.container.teamidentifier=G69SCX94XU
application.datafolder.name=duck

# Lowercase folder name to use when looking for bookmarks in user support directory
bookmarks.folder.name=Bookmarks
# Register file watcher in bookmark folders
bookmarks.folder.monitor=true
# Lowercase folder name to use when looking for profiles in user support directory
profiles.folder.name=Profiles
profiles.discovery.updater.enable=false
profiles.discovery.updater.url=s3://profiles.cyberduck.io

# Maximum number of directory listings to cache using a most recently used implementation
browser.cache.size=1000
transfer.cache.size=100
icon.cache.size=200
preferences.cache.size=1000
fileid.cache.size=10000

# Caching NS* proxy instances.
browser.model.cache.size=10000

# Callback threshold
browser.list.limit.directory=5000
browser.list.limit.container=100

info.toolbar.selected=0
preferences.toolbar.selected=0

# Current default browser view is outline view (0-List view, 1-Outline view, 2-Column view)
browser.view=1
# Save browser sessions when quitting and restore upon relaunch
browser.serialize=true
browser.font.size=12
browser.view.autoexpand=true
browser.view.autoexpand.delay.enable=true
# in seconds
browser.view.autoexpand.delay=1.0
browser.hidden.regex=\\..*
browser.filter.regex=^[\\.]{1,2}$ .*[:/\\\\].*
browser.open.untitled=true
browser.open.bookmark.default=
# Confirm closing the browsing connection
browser.disconnect.confirm=false
browser.disconnect.bookmarks.show=false
# Display only one info panel and change information according to selection in browser
browser.info.inspector=true
browser.sort.ascending=true
browser.alternatingRows=false
browser.verticalLines=false
browser.horizontalLines=true
# Show hidden files in browser by default
browser.showHidden=false
browser.charset.encoding=UTF-8
# Edit double clicked files instead of downloading
browser.doubleclick.edit=false
# Rename files when return or enter key is pressed
browser.enterkey.rename=true
# Enable inline editing in browser
browser.editable=true
# Warn before renaming files
browser.move.confirm=true
browser.copy.confirm=false
browser.transcript.open=false
browser.transcript.size.height=200
# Filename (Short Date Format)Extension
browser.duplicate.format={0} ({1}){2}
browser.delete.trash=true
# Use octal or decimal file sizes
browser.filesize.decimal=false
browser.date.natural=true

bookmark.toggle.options=false
transfer.toggle.details=true

# Default editor
editor.bundleIdentifier=
editor.alwaysUseDefault=false
editor.upload.permissions.change=true
editor.upload.symboliclink.resolve=true

# Save bookmarks in ~/Library
favorites.save=true

queue.removeItemWhenComplete=false
# Default transfer connection handling
queue.transfer.type.enabled=browser newconnection concurrent
queue.transfer.type=concurrent
queue.transfer.operationbatcher.size=100
# Warning when number of transfers in queue exceeds limit
queue.size.warn=20
# Bring transfer window to front
queue.window.open.default=false
queue.window.open.transfer.start=true
queue.window.open.transfer.stop=false
# Action when duplicate file exists
queue.download.action=ask
queue.upload.action=ask
queue.copy.action=ask
# When triggered manually using 'Reload' in the Transfer window
queue.download.reload.action=ask
queue.upload.reload.action=ask
queue.copy.reload.action=ask
queue.upload.permissions.change=false
queue.upload.acl.change=true
queue.upload.permissions.default=false
queue.upload.permissions.file.default=644
queue.upload.permissions.folder.default=755
queue.upload.timestamp.change=false
# Keep existing headers
queue.upload.file.metadata.change=true
queue.upload.file.encryption.change=true
queue.upload.file.redundancy.change=true
queue.upload.checksum.calculate=false
queue.upload.skip.enable=true
queue.upload.skip.regex.default=.*~\\..*|\\.DS_Store|\\.svn|CVS|\\.git|\\.gitignore|\\.gitattributes|\\.bzr|\\.bzrignore|\\.bzrtags|\\.hg|\\.hgignore|\\.hgtags
queue.upload.skip.regex=.*~\\..*|\\.DS_Store|\\.svn|CVS|\\.git|\\.gitignore|\\.gitattributes|\\.bzr|\\.bzrignore|\\.bzrtags|\\.hg|\\.hgignore|\\.hgtags
queue.upload.priority.regex=
# Create temporary filename with an UUID and rename when upload is complete
queue.upload.file.temporary=false
# Format string for temporary filename. Default to filename-uuid
queue.upload.file.temporary.format={0}-{1}
queue.upload.file.rename.format={0} ({1}){2}
queue.download.file.rename.format={0} ({1}){2}
queue.download.permissions.change=true
queue.download.permissions.default=false
queue.download.permissions.file.default=644
queue.download.permissions.folder.default=755
queue.download.timestamp.change=true
queue.download.checksum.calculate=false
queue.download.skip.enable=true
queue.download.skip.regex.default=.*~\\..*|\\.DS_Store|\\.svn|CVS|RCS|SCCS|\\.git|\\.bzr|\\.bzrignore|\\.bzrtags|\\.hg|\\.hgignore|\\.hgtags|_darcs|\\.file-segments
queue.download.skip.regex=.*~\\..*|\\.DS_Store|\\.svn|CVS|RCS|SCCS|\\.git|\\.bzr|\\.bzrignore|\\.bzrtags|\\.hg|\\.hgignore|\\.hgtags|_darcs|\\.file-segments
queue.download.priority.regex=
queue.download.folder=
queue.download.quarantine=true
queue.download.wherefrom=true
# Segmented concurrent downloads
queue.download.segments=true
queue.download.segments.threshold=10485760
queue.download.segments.size=134217728
queue.download.segments.count=128
# Open completed downloads
queue.download.complete.open=false
queue.dock.badge=false
queue.sleep.prevent=true
# Bandwidth throttle options
queue.bandwidth.options=5000,10000,20000,50000,100000,150000,200000,500000,1000000,2000000,5000000,10000000,15000000,20000000,50000000,100000000
# Bandwidth throttle upload stream
queue.upload.bandwidth.bytes=-1
# Bandwidth throttle download stream
queue.download.bandwidth.bytes=-1
# Concurrent connections for single transfer and maximum number of concurrent transfers in transfer list
queue.connections.limit=0
queue.connections.limit.default=5
queue.connections.limit.ftp=1
# Auto determine number of connections
queue.connections.options=0,1,2,3,4,5,10,15,20

# While downloading, update the icon of the downloaded file as a progress indicator
queue.download.icon.update=true
queue.download.icon.threshold=5242880

# Default synchronize action selected in the sync dialog
queue.prompt.sync.action.default=mirror
queue.prompt.download.action.default=overwrite
queue.prompt.upload.action.default=overwrite
queue.prompt.copy.action.default=overwrite
queue.prompt.move.action.default=overwrite

queue.transcript.open=false
queue.transcript.size.height=200

http.compression.enable=true

# HTTP routes to maximum number of connections allowed for those routes
http.connections.route=10
http.connections.reuse=true
http.connections.stale.check.ms=5000

# Total number of connections in the pool
http.connections.total=2147483647
http.connections.retry=1

# Infinite
http.manager.timeout=0
http.socket.buffer=8192
http.credentials.charset=UTF-8
http.request.uri.normalize=false

# Enable or disable verification that the remote host taking part
# of a data connection is the same as the host to which the control
# connection is attached.
ftp.datachannel.verify=false

# Always use EPSV also for IPv4
ftp.datachannel.epsv=false
ftp.socket.buffer=0

ftp.parser.multiline.strict=false
ftp.parser.reply.strict=false
ftp.parser.mlsd.perm.enable=false

# Send LIST -a
ftp.command.lista=true
ftp.command.stat=true
ftp.command.mlsd=true

# Fallback to active or passive mode respectively
ftp.connectmode.fallback=false

# Protect the data channel by default. For TLS, the data connection can have one of two security levels.
# 1) Clear (requested by 'PROT C')
# 2) Private (requested by 'PROT P')
ftp.tls.datachannel=P
ftp.tls.session.requirereuse=true
ftp.ssl.session.cache.size=100

# Try to determine the timezone automatically using timestamp comparison from MLST and LIST
ftp.timezone.auto=false
ftp.timezone.default=

# Authentication header version
# s3.signature.version=AWS2
s3.signature.version=AWS4HMACSHA256

# Default bucket location
s3.location=us-east-1
s3.bucket.virtualhost.disable=false
s3.bucket.requesterpays=true
s3.domain=amazonaws.com
s3.hostname.default=s3.amazonaws.com
s3.endpoint.dualstack.enable=true
s3.endpoint.format.ipv4=s3.%s.amazonaws.com
s3.endpoint.format.ipv6=s3.dualstack.%s.amazonaws.com

s3.acl.default=private

# Default redundancy level
s3.storage.class=STANDARD
s3.storage.class.options=STANDARD
# s3.encryption.algorithm=AES256
s3.encryption.algorithm=

# Validity for public S3 URLs
s3.url.expire.seconds=86400

s3.listing.chunksize=1000
s3.listing.concurrency=25
s3.listing.versioning.enable=true

# Read metadata of every file in list service to display modification date stored in metadata
s3.listing.metadata.enable=false

s3.upload.multipart=true
s3.upload.multipart.lookup=true
s3.upload.multipart.concurrency=10
s3.upload.multipart.partsize.minimum=5242880
# Threshold in bytes. Only use multipart uploads for files more than 100MB
s3.upload.multipart.threshold=104857600
s3.upload.multipart.required.threshold=5368709120
# Maximum number of parts is 10'000. With 10MB segements this gives a maximum object size of 100GB
# Must be a multiple of org.cryptomator.cryptolib.v1.Constants.PAYLOAD_SIZE when using Cryptomator Vaults
# 10MB
s3.upload.multipart.size=10485760
# 100MB
s3.copy.multipart.size=104857600

s3.upload.expect-continue=true

s3.timestamp.enable=false

s3.accelerate.enable=true
s3.accelerate.prompt=false

s3.versioning.enable=true

# Standard,Bulk,Expedited
s3.glacier.restore.tier=Standard
s3.glacier.restore.expiration.days=2
s3.lifecycle.transition.class=GLACIER

# A prefix to apply to log file names
s3.logging.prefix=logs/
google.logging.prefix=log
cloudfront.logging.prefix=logs/

googlestorage.listing.chunksize=1000
googlestorage.listing.concurrency=25
googlestorage.listing.versioning.enable=true
googlestorage.metadata.default=
googlestorage.storage.class=STANDARD
googlestorage.storage.class.options=STANDARD MULTI_REGIONAL REGIONAL NEARLINE COLDLINE ARCHIVE
googlestorage.lifecycle.transition.class=ARCHIVE
googlestorage.acl.default=private
googlestorage.location=us
googlestorage.versioning.enable=true

onedrive.listing.chunksize=1000
# The size of each byte range MUST be a multiple of 320 KiB (327,680 bytes). Using a fragment size that does not
# divide evenly by 320 KiB will result in errors committing some files.
onedrive.upload.multipart.partsize.minimum=327680
# A byte range size of 10 MiB for stable high speed connections is optimal.
# For slower or less reliable connections you may get better results from a smaller fragment size.
# The recommended fragment size is between 5-10 MiB.
# ~6,25 MB
onedrive.upload.multipart.partsize.factor=20
onedrive.timestamp.enable=true

sharepoint.lock.enable=true

# 30 days in seconds
s3.cache.seconds=2592000

# Default metadata for uploads. Format must be "key1=value1 key2=value2"
s3.metadata.default=

s3.lifecycle.transition.options=1 7 10 30 60 180 360 720
s3.lifecycle.delete.options=1 7 10 30 60 180 360 720

s3.delete.multiple.partition=1000

azure.metadata.default=
azure.listing.chunksize=1000
azure.upload.md5=false
azure.upload.snapshot=false
azure.upload.blobtype=APPEND_BLOB

# Legacy authentication
#        openstack.authentication.context=/v1.0
# Keystone authentication
openstack.authentication.context=/v2.0/tokens
openstack.metadata.default=
openstack.list.container.limit=100
openstack.list.object.limit=10000
openstack.account.preload=true
openstack.cdn.preload=true
openstack.container.size.preload=true
openstack.upload.largeobject=true
openstack.upload.largeobject.concurrency=5
openstack.upload.largeobject.segments.prefix=.file-segments/
# 2GB
openstack.upload.largeobject.threshold=2147483648
# 5GB
openstack.upload.largeobject.required.threshold=5368709120
# 1GB
openstack.upload.largeobject.size=1048576000
# Each segment, except for the final one, must be at least 1 megabyte
# 1MB
openstack.upload.largeobject.size.minimum=1048576
# Remove segments when deleting large object manifest
openstack.upload.largeobject.cleanup=true
openstack.delete.multiple.partition=10000
openstack.delete.largeobject.segments=true

googledrive.list.limit=1000
googledrive.teamdrive.enable=true
# Limit the number of requests to 10 per second which is equal the user quota
googledrive.limit.requests.enable=true
googledrive.limit.requests.second=100
googledrive.delete.multiple.partition=50

b2.bucket.acl.default=allPrivate
b2.listing.chunksize=1000
b2.listing.versioning.enable=true
b2.upload.checksum.verify=true
b2.upload.largeobject=true
b2.upload.largeobject.concurrency=5
# 5GB
b2.upload.largeobject.required.threshold=5368709120
# When uploading files larger than 200MB, use the large files support to break up the files into parts and upload the parts in parallel.
# 200MB
b2.upload.largeobject.threshold=209715200
# Each part can be anywhere from 100MB to 5GB in size
b2.upload.largeobject.size=104857600
b2.upload.largeobject.size.minimum=5242880
# 5MB
b2.copy.largeobject.size=5242880
# 10MB
b2.copy.largeobject.threshold=10485760
b2.metadata.default=

sds.version.lts=4.12
sds.listing.chunksize=500
sds.upload.multipart.chunksize=5242880
# Run missing file keys in bulk feature after upload
sds.encryption.missingkeys.upload=true
# 2 minutes
sds.encryption.missingkeys.scheduler.period=120000
sds.encryption.missingkeys.delete.deprecated=false
# 10 minutes
sds.encryption.keys.ttl=600000
# 1 hour
sds.useracount.ttl=3600000
sds.create.dataroom.enable=true
sds.create.dataroom.encrypt=false
sds.delete.dataroom.enable=true
sds.upload.sharelinks.keep=true
sds.upload.s3.enable=true
# In millis
sds.upload.s3.status.delay=50
# In millis
sds.upload.s3.status.period=100
# 30sec in millis
sds.upload.s3.status.interrupt.ms=30000

# 1 minute
spectra.retry.delay=60

storegate.listing.chunksize=500
storegate.upload.multipart.chunksize=524288
# 24 hours
storegate.lock.ttl=86400000
# login_hint parameter
storegate.login.hint=

# Mobile
ctera.attach.devicetype=DriveConnect

oauth.browser.open.warn=false

brick.pairing.nickname.configure=false
brick.pairing.hostname.configure=true
brick.pairing.interval.ms=1000
# 10min
brick.pairing.interrupt.ms=600000
brick.migration.interval.ms=500
# 10sec
brick.migration.interrupt.ms=10000
brick.listing.chunksize=1000
# 10MB
brick.upload.multipart.size=10485760
brick.upload.multipart.concurrency=10

dropbox.upload.chunksize=157286400
dropbox.business.enable=true
dropbox.delete.poll.interval.ms=500
dropbox.limit.requests.enable=false
dropbox.limit.requests.second=100

# NTLM Windows Domain
webdav.ntlm.domain=
webdav.ntlm.workstation=
# Enable Integrated Windows Authentication (IWA) for target server authentication
webdav.ntlm.windows.authentication.enable=false
# Enable preemptive authentication if valid credentials are found
webdav.basic.preemptive=true
# Enable Expect-Continue handshake
webdav.expect-continue=true
webdav.redirect.GET.follow=true
webdav.redirect.HEAD.follow=true
webdav.redirect.PUT.follow=false
webdav.redirect.PROPFIND.follow=true
webdav.metadata.default=
webdav.microsoftiis.header.translate=true
webdav.list.handler.sax=true
webdav.lock.enable=true
webdav.listing.chunksize=20

# Session pool
connection.pool.minidle=1
connection.pool.maxidle=5
connection.pool.maxtotal=2147483647
# Default login name
connection.login.name=
connection.login.anon.name=anonymous
connection.login.anon.pass=cyberduck@example.net
# Search for passphrases in Keychain
connection.login.keychain=true

connection.port.default=21
connection.protocol.default=ftp
# SO_KEEPALIVE
connection.socket.keepalive=true
# SO_LINGER
connection.socket.linger=false
# Socket timeout
connection.timeout.seconds=30
# Retry to connect after a I/O failure automatically
connection.retry=1
connection.retry.max=20
# In seconds
connection.retry.delay=0
connection.retry.backoff.enable=false

connection.hostname.default=
# Convert hostname to Punycode
connection.hostname.idn=true
# java.net.preferIPv6Addresses
connection.dns.ipv6=false
# Read proxy settings from system preferences
connection.proxy.enable=true
connection.proxy.ntlm.domain=

# Integrated Windows Authentication (IWA)
connection.proxy.windows.authentication.enable=false
# Warning when opening connections sending credentials in plaintext
connection.unsecure.warning.ftp=true
connection.unsecure.warning.http=true
connection.ssl.provider.bouncycastle.position=1
# Register bouncy castle as preferred provider. Used in Cyptomator, SSL and SSH
connection.ssl.protocols=TLSv1.3,TLSv1.2,TLSv1.1,TLSv1
connection.ssl.protocols.ftp=TLSv1.2,TLSv1.1,TLSv1
connection.ssl.cipher.blacklist=
connection.ssl.x509.revocation.online=false
# Default secure random strong algorithm
connection.ssl.securerandom.algorithm=NativePRNG
connection.ssl.securerandom.provider=SUN
connection.ssl.keystore.type=
connection.ssl.keystore.provider=

# Transfer read buffer size
connection.chunksize=32768
# Buffer size for wrapped buffered streams
connection.buffer=8192
# SO_SNDBUF
connection.buffer.send=0
# SO_RCVBUF
connection.buffer.receive=0

disk.unmount.timeout=2

# Read favicon from Web URL
bookmark.favicon.download=true
# Default to large icon size
bookmark.icon.size=64
bookmark.menu.icon.size=64

# Location of the openssh known_hosts file
ssh.knownhosts=~/.ssh/known_hosts
ssh.knownhosts.hostname.hash=false

ssh.authentication.publickey.default.enable=false
ssh.authentication.publickey.default.rsa=~/.ssh/id_rsa
ssh.authentication.publickey.default.dsa=~/.ssh/id_dsa
ssh.authentication.agent.enable=true

ssh.heartbeat.provider=keep-alive
ssh.heartbeat.seconds=60

# Enable ZLIB compression
ssh.compression=zlib

ssh.algorithm.cipher.blacklist=
ssh.algorithm.mac.blacklist=
ssh.algorithm.kex.blacklist=
ssh.algorithm.signature.blacklist=

sftp.read.maxunconfirmed=64
sftp.write.maxunconfirmed=64
sftp.write.chunksize=32768
sftp.permissions.server.blacklist=OpenSSH_for_Windows
sftp.listing.chunksize=20

archive.default=tar.gz

# Archiver
archive.command.create.tar=cd {2}; tar -cpPf {0}.tar {1}
archive.command.create.tar.gz=cd {2}; tar -czpPf {0}.tar.gz {1}
archive.command.create.tar.bz2=cd {2}; tar -cjpPf {0}.tar.bz2 {1}
archive.command.create.zip=cd {2}; zip -qr {0}.zip {1}
archive.command.create.gz=gzip -qr {1}
archive.command.create.bz2=bzip2 -zk {1}

# Unarchiver
archive.command.expand.tar=tar -xpPf {0} -C {1}
archive.command.expand.tar.gz=tar -xzpPf {0} -C {1}
archive.command.expand.tar.bz2=tar -xjpPf {0} -C {1}
archive.command.expand.zip=unzip -qn {0} -d {1}
archive.command.expand.gz=gzip -d {0}
archive.command.expand.bz2=bzip2 -dk {0}

update.feed=release
update.feed.nightly.enable=true
update.feed.beta.enable=true

update.check=true
# periodic update check in seconds
update.check.interval=86400
# Last update check in milliseconds
update.check.timestamp=0
terminal.bundle.identifier=com.apple.Terminal
terminal.command.ssh=ssh -t {0} {1}@{2} -p {3} \"cd {4} && exec \\$SHELL -l\"
threading.pool.size.max=20
threading.pool.keepalive.seconds=60
cryptomator.enable=true
cryptomator.vault.version=8
cryptomator.vault.autodetect=true
# Load and add to registry when vault is referenced in file attributes
cryptomator.vault.autoload=true
cryptomator.vault.masterkey.filename=masterkey.cryptomator
cryptomator.vault.config.filename=vault.cryptomator
cryptomator.vault.pepper=
cryptomator.cache.size=1000
# Save passwords for vaults in Keychain
cryptomator.vault.keychain=false
# 4MB
eue.upload.multipart.size=4194304
# 4MB
eue.upload.multipart.threshold=4194304
eue.upload.multipart.concurrency=10
eue.listing.chunksize=100
# 1 year
eue.share.expiration.millis=31540000000
eue.share.deletable=false
eue.share.writable=false
eue.share.readable=true
eue.share.notification.enable=false
eue.limit.hint.second=2
eue.limit.requests.enable=true
# 168 requests per minute by default allowed by server
eue.limit.requests.second=3
# 10 minutes
eue.shares.ttl=600000
eue.delete.multiple.partition=100

# Must be at least 20MB
box.upload.multipart.threshold=20971520
box.upload.multipart.concurrency=10
box.listing.chunksize=100

preferences.general.enable=true
preferences.browser.enable=true
preferences.queue.enable=true
preferences.s3.enable=true
preferences.googlestorage.enable=true
preferences.sftp.enable=true
preferences.ftp.enable=true
preferences.profiles.enable=true
preferences.editor.enable=true
preferences.connection.enable=true
preferences.bandwidth.enable=true
preferences.language.enable=true
preferences.update.enable=true
preferences.cryptomator.enable=true

info.general.enable=true
info.permissions.enable=true
info.acl.enable=true
info.distribution.enable=true
info.s3.enable=true
info.metadata.enable=true
info.versions.enable=true
